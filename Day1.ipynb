{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tracing"
      ],
      "metadata": {
        "id": "1-eAzqwVZeMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"PUT YOURS HERE\""
      ],
      "metadata": {
        "id": "OSmN3fiSZfs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started"
      ],
      "metadata": {
        "id": "vFY9j5sphPKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's invoke the Gemini with a simple text input:"
      ],
      "metadata": {
        "id": "eVuy31nOhRZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbREhv7fgLAG"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "Rb263mc9g1gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=google_api_key)"
      ],
      "metadata": {
        "id": "kjYpwP5NgYOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import Runnable\n",
        "isinstance(llm, Runnable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXWF2rhmgm10",
        "outputId": "485679cf-3e61-457d-a7b3-7c91ad2ac0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"What is the capital of the USA?\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWF1ARONgtNa",
        "outputId": "22acb269-23e0-4392-9632-3eb956dfa0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of the USA is **Washington, D.C.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LXQY5QUEg0Fy",
        "outputId": "6fac72ac-3158-43a2-a340-f20d2f7271dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of the USA is **Washington, D.C.**'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.usage_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk7FS0iahBvf",
        "outputId": "707334d4-7748-405c-c6b8-fa416822ba60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_tokens': 9, 'output_tokens': 42, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 29}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "user_input = HumanMessage(content=\"What is the capital of the USA?\")"
      ],
      "metadata": {
        "id": "EEnlwE3DhXW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step1 = llm.invoke([user_input])"
      ],
      "metadata": {
        "id": "kcGqxRmGhhS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(step1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "B4hfthOzIzLy",
        "outputId": "6b4f9d0a-fd3a-4495-c030-1bde78bebb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "AIMessage is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model together standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 154);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(step1.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q47z6YusI1nI",
        "outputId": "ac092a1a-004b-4d8f-c362-9a12a7ddbaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of the USA is **Washington, D.C.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(step1.usage_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1QwT04PI3AF",
        "outputId": "03c36063-933a-4d5f-b004-d15cda83469a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_tokens': 9, 'output_tokens': 31, 'total_tokens': 40, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 18}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = (\n",
        "    \"Be concise and answer user's question carefully.\\n\\n\"\n",
        "    \"QUESTION:\\n{question}\\n\"\n",
        ")\n",
        "\n",
        "question = \"What is the capital of the USA?\"\n",
        "lc_prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "lc_prompt_template.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iXIAEMlI7OU",
        "outputId": "9bc97b8c-cf82-47e6-c550-5514cfa15c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text=\"Be concise and answer user's question carefully.\\n\\nQUESTION:\\nWhat is the capital of the USA?\\n\")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = lc_prompt_template | llm | StrOutputParser()\n",
        "result = chain.invoke({\"question\": question})"
      ],
      "metadata": {
        "id": "ABrQCaQ5JNnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEtkG5tKiNmF",
        "outputId": "42c1dba1-f447-432a-c977-3a8889e2c4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A special placeholder for messages:"
      ],
      "metadata": {
        "id": "Tp51JXL-KORI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate\n",
        "\n",
        "\n",
        "msg_template = HumanMessagePromptTemplate.from_template(prompt_template)\n",
        "msg_example = msg_template.format(question=question)\n",
        "\n",
        "print(msg_example)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0DkjU2hKNzO",
        "outputId": "cb9a7b69-957c-4915-de8c-3f52b7815559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Be concise and answer user's question carefully.\\n\\nQUESTION:\\nWhat is the capital of the USA?\\n\" additional_kwargs={} response_metadata={}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_template = ChatPromptTemplate.from_messages([SystemMessage(content=\"You are a helpful assistant.\"), msg_template])\n",
        "chain = chat_prompt_template | llm | StrOutputParser()\n",
        "chain.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6xzdD0GKKYXt",
        "outputId": "749bea51-acc0-4998-8861-357951d22eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Washington, D.C.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"You are a helpful assistant.\"),\n",
        "     (\"placeholder\", \"{history}\"),\n",
        "     # same as MessagesPlaceholder(\"history\"),\n",
        "     (\"human\", prompt_template)])"
      ],
      "metadata": {
        "id": "T2ipEzczKfrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_template.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5eUU2TnKh1p",
        "outputId": "5abfe821-b4d0-4a7f-ac4a-945964d21b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Be concise and answer user's question carefully.\\n\\nQUESTION:\\nWhat is the capital of the USA?\\n\", additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chat_prompt_template.invoke(question).messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeBas7GtKlj3",
        "outputId": "3c5eab8a-0d5a-4e15-d42f-ac690a374331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chat_prompt_template.invoke({\"question\": question, \"history\": [(\"user\", \"hi\"), (\"ai\", \"how can I help?\")]}).messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJfrW_jgKqMG",
        "outputId": "99c626e0-6c31-4cf7-d5ae-db9d35bd26ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def increment_by_one(x: int) -> int:\n",
        " return x + 1\n",
        "\n",
        "\n",
        "def fake_llm(x: int) -> str:\n",
        " return f\"Result = {x}\""
      ],
      "metadata": {
        "id": "ANH-OhFBK1hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "chain = (\n",
        "   increment_by_one | RunnableLambda(fake_llm)\n",
        ")\n",
        "\n",
        "\n",
        "result = chain.invoke(1)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9s-IFCgN6ho",
        "outputId": "76b69c70-c4da-4671-8ecf-8a5cc79cbca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableSequence\n",
        "\n",
        "\n",
        "a = increment_by_one | RunnableLambda(fake_llm)\n",
        "b = RunnableSequence(RunnableLambda(increment_by_one), RunnableLambda(fake_llm))\n",
        "\n",
        "print(a == b)\n"
      ],
      "metadata": {
        "id": "MqbUgSBKOKwM",
        "outputId": "bc9b268e-8c6e-4aa5-bec7-317e707227aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.callbacks import UsageMetadataCallbackHandler\n",
        "\n",
        "cb = UsageMetadataCallbackHandler()\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\", google_api_key=google_api_key, callbacks=[cb])"
      ],
      "metadata": {
        "id": "9eL2MLZOOPV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = lc_prompt_template | llm | StrOutputParser()\n",
        "chain.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LuekYPRSRusf",
        "outputId": "8a12b922-3a70-487d-e036-bb6b3327e02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Washington, D.C.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kv0sFJERvft",
        "outputId": "fe2c6dce-ea0b-413f-c819-662250a5ad34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gemini-2.0-flash-001': {'input_tokens': 23, 'output_tokens': 7, 'total_tokens': 30, 'input_token_details': {'cache_read': 0}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to LangGraph"
      ],
      "metadata": {
        "id": "r3ydNlMHr5KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "class CustomState(TypedDict):\n",
        "    a: int\n",
        "    b: int\n",
        "    result: int\n",
        "\n",
        "\n",
        "def _node_a(state):\n",
        "    return {\"a\": 1}\n",
        "\n",
        "def _node_b(state):\n",
        "    return {\"b\": 2}\n",
        "\n",
        "def _node_sum(state):\n",
        "    a = state[\"a\"]\n",
        "    b = state[\"b\"]\n",
        "    return {\"result\": a+b}\n",
        "\n",
        "builder = StateGraph(CustomState)\n",
        "builder.add_node(\"node_a\", _node_a)\n",
        "builder.add_node(\"node_b\", _node_b)\n",
        "builder.add_node(\"node_sum\", _node_sum)\n",
        "\n",
        "builder.add_edge(START, \"node_a\")\n",
        "builder.add_edge(START, \"node_b\")\n",
        "builder.add_edge(\"node_a\", \"node_sum\")\n",
        "builder.add_edge(\"node_b\", \"node_sum\")\n",
        "builder.add_edge(\"node_sum\", END)\n",
        "\n",
        "workflow = builder.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(workflow.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "wXX4tGjfr6xA",
        "outputId": "8e616fce-be62-475c-d13e-4514b95a7267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1825955264.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_mermaid_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph.py\u001b[0m in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mfrontmatter_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrontmatter_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         )\n\u001b[0;32m--> 695\u001b[0;31m         return draw_mermaid_png(\n\u001b[0m\u001b[1;32m    696\u001b[0m             \u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph_mermaid.py\u001b[0m in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    292\u001b[0m         )\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdraw_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMermaidDrawMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         img_bytes = _render_mermaid_using_api(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph_mermaid.py\u001b[0m in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34mf\"your graph. Status code: {response.status_code}.\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             ) + error_msg_suffix\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in workflow.stream({}, stream_mode=\"values\"):\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13IekX73zFaz",
        "outputId": "88b01d09-a5ac-4c10-e81e-e3b94c07e5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'b': 2}\n",
            "{'a': 1, 'b': 2, 'result': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "\n",
        "class CustomState(TypedDict):\n",
        "    operation: str\n",
        "    a: int\n",
        "    b: int\n",
        "    result: int\n",
        "\n",
        "def _node_multiply(state):\n",
        "    a = state[\"a\"]\n",
        "    b = state[\"b\"]\n",
        "    return {\"result\": a*b}\n",
        "\n",
        "def _edge(state) -> Literal[\"node_sum\", \"node_multiply\"]:\n",
        "    if state[\"operation\"] == \"sum\":\n",
        "      return \"node_sum\"\n",
        "    return \"node_multiply\"\n",
        "\n",
        "builder = StateGraph(CustomState)\n",
        "builder.add_node(\"node_a\", _node_a)\n",
        "builder.add_node(\"node_b\", _node_b)\n",
        "builder.add_node(\"node_sum\", _node_sum)\n",
        "builder.add_node(\"node_multiply\", _node_multiply)\n",
        "\n",
        "builder.add_edge(START, \"node_a\")\n",
        "builder.add_edge(START, \"node_b\")\n",
        "builder.add_conditional_edges(\"node_a\", _edge)\n",
        "builder.add_conditional_edges(\"node_b\", _edge)\n",
        "builder.add_edge(\"node_sum\", END)\n",
        "builder.add_edge(\"node_multiply\", END)\n",
        "\n",
        "workflow = builder.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(workflow.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "D_PpvaYNFEsT",
        "outputId": "022899c8-7e3c-4746-be9c-601607e24e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-331059433.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_mermaid_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph.py\u001b[0m in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mfrontmatter_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrontmatter_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         )\n\u001b[0;32m--> 695\u001b[0;31m         return draw_mermaid_png(\n\u001b[0m\u001b[1;32m    696\u001b[0m             \u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph_mermaid.py\u001b[0m in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    292\u001b[0m         )\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdraw_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMermaidDrawMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         img_bytes = _render_mermaid_using_api(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph_mermaid.py\u001b[0m in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34mf\"your graph. Status code: {response.status_code}.\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             ) + error_msg_suffix\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = {\"operation\": \"add\"}\n",
        "for event in workflow.stream(initial_state, stream_mode=\"values\"):\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcKuzoqzFF8T",
        "outputId": "c358002d-0e63-4f46-f211-59b04d1908ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'operation': 'add'}\n",
            "{'operation': 'add', 'a': 1, 'b': 2}\n",
            "{'operation': 'add', 'a': 1, 'b': 2, 'result': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in workflow.stream({'operation': 'multiply'}, stream_mode=\"values\"):\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvPfUigiFaZo",
        "outputId": "1cf32266-fea7-400d-a7d3-9920b193a4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'operation': 'multiply'}\n",
            "{'operation': 'multiply', 'a': 1, 'b': 2}\n",
            "{'operation': 'multiply', 'a': 1, 'b': 2, 'result': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await workflow.ainvoke(initial_state)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L55piTzpzbyO",
        "outputId": "41c2abea-8a62-4817-cdcb-fc7a707be64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'operation': 'add', 'a': 1, 'b': 2, 'result': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's take at reducers. We saw the default reducer - it replaces the value in the state. Another option is to use a built-in reducer, for example `add` with a list:"
      ],
      "metadata": {
        "id": "_Z47F4MMEclR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import add\n",
        "\n",
        "add([1, 2], [3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1eJTXNJlu75",
        "outputId": "3558ae44-185f-471a-8117-5dec1f61f953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import add\n",
        "from typing import Annotated\n",
        "\n",
        "class CustomState(TypedDict):\n",
        "    values: Annotated[list[int], add]\n",
        "    result: int\n",
        "\n",
        "\n",
        "def _node_a(state):\n",
        "    return {\"values\": [1]}\n",
        "\n",
        "def _node_b(state):\n",
        "    return {\"values\": [2]}\n",
        "\n",
        "def _node_sum(state):\n",
        "    return {\"result\": sum(state[\"values\"])}\n",
        "\n",
        "builder = StateGraph(CustomState)\n",
        "builder.add_node(\"node_a\", _node_a)\n",
        "builder.add_node(\"node_b\", _node_b)\n",
        "builder.add_node(\"node_sum\", _node_sum)\n",
        "\n",
        "builder.add_edge(START, \"node_a\")\n",
        "builder.add_edge(\"node_a\", \"node_b\")\n",
        "builder.add_edge(\"node_b\", \"node_sum\")\n",
        "builder.add_edge(\"node_sum\", END)\n",
        "\n",
        "workflow = builder.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(workflow.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "z6v3YakjEMav",
        "outputId": "a5ceb75a-8b3e-49df-e6f5-fa9fe06197aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-919396344.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_mermaid_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph.py\u001b[0m in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mfrontmatter_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrontmatter_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         )\n\u001b[0;32m--> 695\u001b[0;31m         return draw_mermaid_png(\n\u001b[0m\u001b[1;32m    696\u001b[0m             \u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph_mermaid.py\u001b[0m in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    292\u001b[0m         )\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdraw_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMermaidDrawMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         img_bytes = _render_mermaid_using_api(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mmermaid_syntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/graph_mermaid.py\u001b[0m in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34mf\"your graph. Status code: {response.status_code}.\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             ) + error_msg_suffix\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in workflow.stream({}, stream_mode=\"values\"):\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZELGTJDfGAjv",
        "outputId": "90bd1c38-8db2-455b-c3c3-cf23a37e0123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'values': [1]}\n",
            "{'values': [1, 2]}\n",
            "{'values': [1, 2], 'result': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's take a look at custom reducers:"
      ],
      "metadata": {
        "id": "L11YZ0T0Gmrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_reducer(left: int, right: int) -> int:\n",
        "  if right:\n",
        "    return left + right\n",
        "  return left"
      ],
      "metadata": {
        "id": "BhY8hybpGOBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import add\n",
        "from typing import Annotated\n",
        "\n",
        "class CustomState(TypedDict):\n",
        "    value: Annotated[int, my_reducer]\n",
        "\n",
        "\n",
        "def _node_a(state):\n",
        "    return {\"value\": 1}\n",
        "\n",
        "def _node_b(state):\n",
        "    return {\"value\": 2}\n",
        "\n",
        "builder = StateGraph(CustomState)\n",
        "builder.add_node(\"node_a\", _node_a)\n",
        "builder.add_node(\"node_b\", _node_b)\n",
        "\n",
        "builder.add_edge(START, \"node_a\")\n",
        "builder.add_edge(\"node_a\", \"node_b\")\n",
        "builder.add_edge(\"node_b\", END)\n",
        "\n",
        "workflow = builder.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(workflow.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "DarbOmATGZGA",
        "outputId": "4430676f-0e1d-4331-abb6-65e55e965105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in workflow.stream({}, stream_mode=\"values\"):\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEMi_n_SGgNn",
        "outputId": "b0a4c6dd-455b-401e-a465-19a67deb1887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'values': [1]}\n",
            "{'values': [1, 2]}\n",
            "{'values': [1, 2], 'result': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step2 = llm.invoke([user_input, step1, (\"human\", \"How many people live there?\")])"
      ],
      "metadata": {
        "id": "9g2EZH_Xhk8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(step2.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMJMoHr1hqj1",
        "outputId": "003563fb-3be4-4add-bf74-d53ee0167caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The population of Washington, D.C. is estimated to be around **689,545** as of 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tracing"
      ],
      "metadata": {
        "id": "Mvnz8m_DMMmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\", google_api_key=google_api_key)\n",
        "result = llm.invoke(\"What is the capital of the USA?\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfd9iVl7Jr-u",
        "outputId": "3e3234da-1efb-45bf-dbed-430d7b0ff547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of the USA is **Washington, D.C.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "@traceable\n",
        "def run():\n",
        "  return llm.invoke(\"What is the capital of the USA?\")"
      ],
      "metadata": {
        "id": "T3baOgBiJ_J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client, tracing_context, traceable\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "langsmith_client = Client(\n",
        "  api_key=userdata.get('LANGSMITH_API_KEY'),\n",
        "  api_url=\"https://api.smith.langchain.com\"\n",
        ")"
      ],
      "metadata": {
        "id": "oyOIhP0sKinK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tracing_context(enabled=True):\n",
        "  result = llm.invoke(\"What is the capital of the USA?\")"
      ],
      "metadata": {
        "id": "bCLB7583Kum7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"What is the capital of UK?\")"
      ],
      "metadata": {
        "id": "Nb0XzmgdK-K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using external tools"
      ],
      "metadata": {
        "id": "CKQKlH4Ehs0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "k923Q9sIhvGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's demonstrate how we can instruct an LLM to use an external tool:"
      ],
      "metadata": {
        "id": "JGUb7713i7Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = (\n",
        "    \"In 1990, the average cost of a gallon of gasoline was $1.16. If the \"\n",
        "    \"inflation rate from 1990 to today has been a cumulative 180%, what would \"\n",
        "    \"that gallon of gas cost in today's money? How does that compare to the \"\n",
        "    \"current average price of gas?\"\n",
        ")\n",
        "\n",
        "raw_prompt_template = (\n",
        "  \"You have access to search engine that provides you an \"\n",
        "  \"information about current events. \"\n",
        "  \"Given the question, decide whether you need an additional \"\n",
        "  \"information from the search engine, and if yes, reply with 'SEARCH: \"\n",
        "   \"<generated query>'. Only if you know enough to answer the user \"\n",
        "   \"then reply with 'RESPONSE <final response>').\\n\"\n",
        "   \"Now, act to answer a user question:\\n{question}\"\n",
        ")\n",
        "prompt_template = PromptTemplate.from_template(raw_prompt_template)\n",
        "\n",
        "response = (prompt_template | llm).invoke(task)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh4Wd-G3h4Y1",
        "outputId": "843b014c-5d17-4ce8-f07a-fb671c3ba1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEARCH: average gas price today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technical note: a _PromptTemplate_ allows you substitute variables when executing the chain:"
      ],
      "metadata": {
        "id": "Z3REc5mrkpWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.invoke({\"question\": \"TEST\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07_b8fCHkup9",
        "outputId": "f714fe31-944f-49bc-b072-3cebfd0fe0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text=\"You have access to search engine that provides you an information about current events. Given the question, decide whether you need an additional information from the search engine, and if yes, reply with 'SEARCH: <generated query>'. Only if you know enough to answer the user then reply with 'RESPONSE <final response>').\\nNow, act to answer a user question:\\nTEST\")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"average gas price today\"\n",
        "search_result = \"3.349\""
      ],
      "metadata": {
        "id": "SkYzBWspmWN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_prompt_template = (\n",
        "  \"You have access to search engine that provides you an \"\n",
        "  \"information about current events. \"\n",
        "  \"Given the question, decide whether you need an additional \"\n",
        "  \"information from the search engine, and if yes, reply with 'SEARCH: \"\n",
        "   \"<generated query>'. Only if you know enough to answer the user \"\n",
        "   \"then reply with 'RESPONSE <final response>').\\n\"\n",
        "   #\"Today is {date}.\"\n",
        "   \"Now, act to answer a user question and \"\n",
        "   \"take into account your previous actions:\\n\"\n",
        "   \"HUMAN: {question}\\n\"\n",
        "   \"AI: SEARCH: {query}\\n\"\n",
        "   \"RESPONSE FROM SEARCH: {search_result}\\n\"\n",
        ")\n",
        "prompt_template = PromptTemplate.from_template(raw_prompt_template)\n",
        "\n",
        "result = (prompt_template | llm).invoke({\"question\": task, \"query\": query, \"search_result\": search_result, \"date\": \"Feb 2025\"})\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K4EDs_XlAYu",
        "outputId": "14a2fcb3-0d4c-438d-ebf7-8b9c86cc2be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE: With a cumulative inflation rate of 180% from 1990, a gallon of gas that cost $1.16 in 1990 would cost $3.25 in today's money (1.16 * 2.80 = 3.248). The current average price of gas is $3.35, which is about 10 cents more than the inflation-adjusted price from 1990.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating tools with LangChain"
      ],
      "metadata": {
        "id": "jDUNa8RKmoIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use a DuckDuckGo search through LangChain:"
      ],
      "metadata": {
        "id": "6DY35rHYm9XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "print(f\"Tool's name = {search.name}\")\n",
        "print(f\"Tool's name = {search.description}\")\n",
        "print(f\"Tool's arg schema = {search.args_schema}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5m-A_wCmpz4",
        "outputId": "bc50fabe-a911-4ce7-95a6-453897ef59b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool's name = duckduckgo_search\n",
            "Tool's name = A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "Tool's arg schema = <class 'langchain_community.tools.ddg_search.tool.DDGInput'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.ddg_search.tool import DDGInput\n",
        "\n",
        "print(DDGInput.model_fields)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbKbhjk-m8u3",
        "outputId": "66a8cb24-1089-4f53-eea0-94394c98f0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': FieldInfo(annotation=str, required=True, description='search query to look up')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the weather in Munich like tomorrow?\"\n",
        "search_input = DDGInput(query=query)\n",
        "result = search.invoke(search_input.model_dump())\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWxbW_j4nFP1",
        "outputId": "50a3cb9e-7657-4d95-a723-ca37ddcd46e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything you need to know about tomorrow ' s weather in Munich , Bavaria, Germany. High/Low, Precipitation Chances, Sunrise/Sunset, and tomorrow 's Temperature History. Aug 28, 2025 · Munich , Germany - Detailed weather forecast for tomorrow . Hourly forecast for tomorrow - including weather conditions, temperature, pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data. 3 days ago · Get the latest hourly weather updates for Munich tomorrow . Detailed forecast including temperature, wind, rain, snow, and UV index. Stay informed about tomorrow 's weather conditions in Munich . Aug 27, 2025 · Latest weather forecast for Munich for tomorrow 's, hourly weather forecast, including tomorrow 's temperatures in Munich , wind, rain and more. Current weather in Munich and forecast for today, tomorrow , and next 14 days Nov 27, 2024 · Geomagnetic activity Kp index tomorrow Forecast of geomagnetic activity for tomorrow . Three-hour forecast of the Kp planetary index The highest geomagnetic activity index tomorrow is predicted to be 2 points. No geomagnetic storms are not expected tomorrow . Get accurate hourly forecasts for today, tonight, and tomorrow , along with 10-day daily forecasts and weather radar for Munich , Bavaria, Germany with MSN Weather . Stay updated on... Current weather in Munich and forecast for today, tomorrow , and next 14 days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "isinstance(result, str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnl266NKnKGd",
        "outputId": "e7a60921-189d-4f30-b968-d55f4bdeced0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another example - let's use a web API to instruct an LLM to get the latest information about FX rates:"
      ],
      "metadata": {
        "id": "ZvfwWJ0VnnWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_spec = \"\"\"\n",
        "openapi: 3.0.0\n",
        "info:\n",
        "  title: Frankfurter Currency Exchange API\n",
        "  version: v1\n",
        "  description: API for retrieving currency exchange rates. Pay attention to the base currency and change it if needed.\n",
        "\n",
        "servers:\n",
        "  - url: https://api.frankfurter.dev/v1\n",
        "\n",
        "paths:\n",
        "  /v1/{date}:\n",
        "    get:\n",
        "      summary: Get exchange rates for a specific date.\n",
        "      parameters:\n",
        "        - in: path\n",
        "          name: date\n",
        "          schema:\n",
        "            type: string\n",
        "            pattern: '^\\d{4}-\\d{2}-\\d{2}$' # YYYY-MM-DD format\n",
        "          required: true\n",
        "          description: The date for which to retrieve exchange rates.  Use YYYY-MM-DD format.  Example: 2009-01-04\n",
        "        - in: query\n",
        "          name: symbols\n",
        "          schema:\n",
        "            type: string\n",
        "          description: Comma-separated list of currency symbols to retrieve rates for. Example: GBP,USD,EUR\n",
        "\n",
        "  /v1/latest:\n",
        "    get:\n",
        "      summary: Get the latest exchange rates.\n",
        "      parameters:\n",
        "        - in: query\n",
        "          name: symbols\n",
        "          schema:\n",
        "            type: string\n",
        "          description: Comma-separated list of currency symbols to retrieve rates for. Example: CHF,GBP\n",
        "        - in: query\n",
        "          name: base\n",
        "          schema:\n",
        "            type: string\n",
        "          description: The base currency for the exchange rates. If not provided, EUR is used as a base currency. Example: USD\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LKDmxcVlnOBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a292bba-853d-4c32-fc43-e88e5f43a64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:20: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:20: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2022118673.py:20: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  pattern: '^\\d{4}-\\d{2}-\\d{2}$' # YYYY-MM-DD format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.agent_toolkits.openapi.toolkit import RequestsToolkit\n",
        "from langchain_community.utilities.requests import TextRequestsWrapper\n",
        "\n",
        "toolkit = RequestsToolkit(\n",
        "    requests_wrapper=TextRequestsWrapper(headers={}),\n",
        "    allow_dangerous_requests=True,\n",
        ")\n",
        "\n",
        "for tool in toolkit.get_tools():\n",
        "  print(tool.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG_Z_-23nv4-",
        "outputId": "6a177b55-a6bb-4aac-a106-535eafd533bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests_get\n",
            "requests_post\n",
            "requests_patch\n",
            "requests_put\n",
            "requests_delete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "system_message = (\n",
        "  \"You're given the API spec:\\n{api_spec}\\n\"\n",
        "  \"If possible, use this API if a user asks about foreign exchange rates. \"\n",
        ")\n",
        "\n",
        "agent = create_react_agent(llm, toolkit.get_tools(), prompt=system_message.format(api_spec=api_spec))"
      ],
      "metadata": {
        "id": "rnEVunSun1em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the swiss franc to US dollar exchange rate?\"\n",
        "\n",
        "for event in agent.stream({\"messages\": [(\"human\", query)]}, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jIQriaOoJrf",
        "outputId": "11159c65-77fe-4946-8827-1ba89405755a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the swiss franc to US dollar exchange rate?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  requests_get (7294e79c-7a71-4276-a7aa-636e8be4aff4)\n",
            " Call ID: 7294e79c-7a71-4276-a7aa-636e8be4aff4\n",
            "  Args:\n",
            "    url: https://api.frankfurter.dev/v1/latest?symbols=USD&base=CHF\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: requests_get\n",
            "\n",
            "{\"amount\":1.0,\"base\":\"CHF\",\"date\":\"2025-09-04\",\"rates\":{\"USD\":1.2413}}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The current exchange rate is 1 CHF = 1.2413 USD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke([\n",
        "    (\"system\", system_message.format(api_spec=api_spec)),\n",
        "     (\"human\", \"What is the swiss franc to US dollar exchange rate?\")], tools=toolkit.get_tools())"
      ],
      "metadata": {
        "id": "b1Wk4graoWyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_calls = response.tool_calls\n",
        "print(tool_calls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcdnCOyXrkL5",
        "outputId": "189d0715-b4c9-410d-be7b-39d762799c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'requests_get', 'args': {'__arg1': 'https://api.frankfurter.dev/v1/latest?symbols=USD&base=CHF'}, 'id': '3aae0067-0560-4a53-9baf-23f73621d4da', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit.get_tools()[0].run(tool_calls[0][\"args\"][\"__arg1\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Ueo6PVMirnCa",
        "outputId": "9ff53f77-cd62-4592-e068-74bdab20693f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"amount\":1.0,\"base\":\"CHF\",\"date\":\"2025-09-04\",\"rates\":{\"USD\":1.2413}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining tools with LangChain"
      ],
      "metadata": {
        "id": "2c-ys0xRGtyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from langchain_core.tools import tool\n",
        "import numexpr as ne\n",
        "\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Calculates a single mathematical expression, incl. complex numbers.\n",
        "\n",
        "    Always add * to operations, examples:\n",
        "      73i -> 73*i\n",
        "      7pi**2 -> 7*pi**2\n",
        "    \"\"\"\n",
        "    math_constants = {\"pi\": math.pi, \"i\": 1j, \"e\": math.exp}\n",
        "    result = ne.evaluate(expression.strip(), local_dict=math_constants)\n",
        "    return str(result)"
      ],
      "metadata": {
        "id": "qi-wbywqGrES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculator.invoke(\"2+2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5U61OrHlGqUB",
        "outputId": "f95fd9c1-cc1b-4b69-962a-7064af5d3cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import BaseTool\n",
        "\n",
        "assert isinstance(calculator, BaseTool)\n",
        "print(f\"Tool name: {calculator.name}\")\n",
        "print(f\"Tool name: {calculator.description}\")\n",
        "print(f\"Tool schema: {calculator.args_schema.model_json_schema()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL1za8A8JVQj",
        "outputId": "9a7d13ba-f5f8-4073-d552-b487be29da76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool name: calculator\n",
            "Tool name: Calculates a single mathematical expression, incl. complex numbers.\n",
            "\n",
            "    Always add * to operations, examples:\n",
            "      73i -> 73*i\n",
            "      7pi**2 -> 7*pi**2\n",
            "Tool schema: {'description': 'Calculates a single mathematical expression, incl. complex numbers.\\n\\nAlways add * to operations, examples:\\n  73i -> 73*i\\n  7pi**2 -> 7*pi**2', 'properties': {'expression': {'title': 'Expression', 'type': 'string'}}, 'required': ['expression'], 'title': 'calculator', 'type': 'object'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculator.args_schema.model_json_schema())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVjhZ_ZF2Hmp",
        "outputId": "4ac0131c-112a-42fb-b4f5-94868b6693bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'description': 'Calculates a single mathematical expression, incl. complex numbers.\\n\\nAlways add * to operations, examples:\\n  73i -> 73*i\\n  7pi**2 -> 7*pi**2', 'properties': {'expression': {'title': 'Expression', 'type': 'string'}}, 'required': ['expression'], 'title': 'calculator', 'type': 'object'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much is 2+3i squared?\"\n",
        "\n",
        "agent = create_react_agent(llm, [calculator])\n",
        "\n",
        "for event in agent.stream({\"messages\": [(\"user\", query)]}, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-r-MQ8vJWQD",
        "outputId": "8281346d-1ec4-49ce-8c0d-8d03ce57208d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How much is 2+3i squared?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  calculator (2ce06133-d609-4393-a75e-d8bcb7d7d322)\n",
            " Call ID: 2ce06133-d609-4393-a75e-d8bcb7d7d322\n",
            "  Args:\n",
            "    expression: (2+3*i)**2\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: calculator\n",
            "\n",
            "(-5+12j)\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "(2+3i)^2 is -5+12j.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = (\n",
        "    #\"I ate 200g of chicken breast, 150g of broccoli, and 50g of brown rice for dinner. \"\n",
        "    \"I ate 200g of chicken breast for dinner. \"\n",
        "    \"How many total calories did I consume, and what percentage of my recommended daily \"\n",
        "    \"protein intake does this meal provide if my recommended intake is 75g?\"\n",
        ")\n",
        "\n",
        "system_hint = \"Think step-by-step. Always use search tool to get the fresh information about events or public facts that can change over time. Always use calculator tool for math computations.\"\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm, [calculator, search],\n",
        "    prompt=system_hint)\n",
        "\n",
        "for event in agent.stream({\"messages\": [(\"user\", question)]}, stream_mode=\"updates\"):\n",
        "    for _, event_values in event.items():\n",
        "      for message in event_values[\"messages\"]:\n",
        "        message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn-Rwg_RJpph",
        "outputId": "2f4f72ab-5070-48ef-b221-b844965475e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  duckduckgo_search (7fc8bed7-28b7-4926-bf60-f3432cf37eab)\n",
            " Call ID: 7fc8bed7-28b7-4926-bf60-f3432cf37eab\n",
            "  Args:\n",
            "    query: calories in 200g chicken breast\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: duckduckgo_search\n",
            "\n",
            "200 grams of chicken breast (Broilers or fryers, meat and skin, cooked, fried, batter) contains 520 Calories . The macronutrient breakdown is 14% carbs, 47% fat, and 39% protein. This has a relatively high calorie density, with 260 Calories per 100g. The following is nutritional content of a 100g serving of chicken breast prepared using different cooking methods: A 100g serving of chicken breast is approximately 3.53 ounces. To convert between grams (g) and ounces (oz), you can use the following conversion formulae: 1 ounce (oz) = 28.34 grams (g) 1 gram (g) = 0.035 ounces (oz) See full list on irastoworldhealth.com The nutritional content of chicken wings prepared using different cooking methods, in 1 piece (about 20-35g) and 100g servings: See full list on irastoworldhealth.com The nutritional content of chicken thighs prepared using different cooking methods, in 1 piece (about 52g) and 100g servings: See full list on irastoworldhealth.com For a healthy adult, with minimal physical activity the allowance is 0.8g per kg body weight per day. To fulfill functional requirements, including the enhancement of skeletal muscle protein synthesis and the development of physical strength, the following is recommended Chicken breast is a high-quality protein source, with a favorable amino acid p... See full list on irastoworldhealth.com How many kcal is 1 chicken breast ? It depends on the weight and preparation. A 3.5 oz (100g) raw chicken breast has about 120 kcal. How many calories in 1, 200g chicken breast ? A 200g raw chicken breast has about 240 kcal (assuming it’s skinless). How many calories in 1, 200g chicken breast with skin? A 200g chicken breast with skin has approximately 348 calories . Keep in mind that this value may vary depending on the cooking method used. See full list on irastoworldhealth.com So we can estimate that 200 grams of cooked chicken breast contains 330 to 380 calories , depending on preparation method. Grilling or baking are lower calorie options compared to frying. Here is the calorie breakdown for a 200 gram serving of baked chicken breast : Chicken skin contains a lot of fat. In 200 grams of cooked chicken breast, there are approximately 330 calories . This makes it a great lean protein source for those looking to maintain a healthy diet. According to the United States Department of Agriculture (USDA), a 200g serving of cooked, skinless chicken breast contains approximately 368 calories . The caloric value of chicken breast primarily comes from its protein content, as protein contains 4 calories per gram, while carbohydrates and fats contain 4 and 9 calories per gram, respectively. Oct 10, 2024 · Chicken breast is low in fat and high in protein, a good choice if you are trying to lose weight or build muscle. A 100-gram chicken breast contains about 165 calories . So we can estimate that 200 grams of cooked chicken breast contains 330 to 380 calories , depending on preparation method. Grilling or baking are lower calorie options compared to frying. Here is the calorie breakdown for a 200 gram serving of baked chicken breast : Chicken skin contains a lot of fat. In 200 grams of cooked chicken breast, there are approximately 330 calories . This makes it a great lean protein source for those looking to maintain a healthy diet. According to the United States Department of Agriculture (USDA), a 200g serving of cooked, skinless chicken breast contains approximately 368 calories . The caloric value of chicken breast primarily comes from its protein content, as protein contains 4 calories per gram, while carbohydrates and fats contain 4 and 9 calories per gram, respectively.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on my search, 200g of cooked chicken breast contains approximately 330-380 calories. I will use 350 calories as an estimate.\n",
            "\n",
            "To calculate the protein content, I need to find the grams of protein in 200g of chicken breast.\n",
            "Tool Calls:\n",
            "  duckduckgo_search (8d81a37c-3315-4468-83f7-62e048b1c206)\n",
            " Call ID: 8d81a37c-3315-4468-83f7-62e048b1c206\n",
            "  Args:\n",
            "    query: protein in 200g chicken breast\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: duckduckgo_search\n",
            "\n",
            "A 200 g serving of chicken breast packs a powerful nutritional punch, providing lean protein and essential nutrients without loading up on calories. Skinless chicken breast reigns as the ultimate protein source among fitness enthusiasts. A 100g portion packs around 31g of protein with minimal fat. Your body digests it efficiently, making it perfect for regular consumption. Chicken breast is primarily composed of protein , but it also contains essential vitamins and minerals.A typical serving ( 200 g ) offers around 62 grams of protein , which is roughly more than half your daily requirement based on a standard diet. High protein foods include lean chicken , lean pork, fish, lean beef, tofu, beans, lentils, low-fat yogurt, milk, cheese, seeds, nuts, and eggs. Below is a list of healthy protein -rich foods sorted by common serving size. Use the protein nutrient ranking to sort by 100 gram or 200 calorie serving... 200 grams grilled chicken calories, grilled chicken breast nutrition, calories in grilled chicken , healthy meal planning, weight loss meal ideas Last updated 2024-12-23.And this is what 200 calories of chicken breast looks like - about 90% of those calories come from protein .\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "A 200g serving of chicken breast contains approximately 330-380 calories, depending on the cooking method. It also contains about 62g of protein.\n",
            "\n",
            "To calculate the percentage of your recommended daily protein intake:\n",
            "\n",
            "(62g protein / 75g recommended intake) * 100% = 82.67%\n",
            "\n",
            "Therefore, your meal provides approximately 82.67% of your recommended daily protein intake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda, RunnableConfig\n",
        "from langchain_core.tools import tool, convert_runnable_to_tool\n",
        "\n",
        "\n",
        "def calculator(expression: str) -> str:\n",
        "    math_constants = {\"pi\": math.pi, \"i\": 1j, \"e\": math.exp}\n",
        "    result = ne.evaluate(expression.strip(), local_dict=math_constants)\n",
        "    return str(result)\n",
        "\n",
        "calculator_with_retry = RunnableLambda(calculator).with_retry(\n",
        "    wait_exponential_jitter=True,\n",
        "    stop_after_attempt=3,\n",
        ")\n",
        "\n",
        "calculator_tool = convert_runnable_to_tool(\n",
        "    calculator_with_retry,\n",
        "    name=\"calculator\",\n",
        "    description=(\n",
        "        \"Calculates a single mathematical expression, incl. complex numbers.\"\n",
        "        \"'\\nAlways add * to operations, examples:\\n73i -> 73*i\\n\"\n",
        "        \"7pi**2 -> 7*pi**2\"\n",
        "    ),\n",
        "    arg_types={\"expression\": \"str\"},\n",
        ")"
      ],
      "metadata": {
        "id": "iF7KAc3vNUSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"How much is (2+3i)**2\", tools=[calculator_tool]).tool_calls[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k6xsDKrNXZz",
        "outputId": "0de8e942-1fe4-4dbd-e94e-006f10057652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'calculator',\n",
              " 'args': {'__arg1': '(2+3*i)**2'},\n",
              " 'id': '6eb16c7a-4ca1-4488-b2c3-4af43d386ddc',\n",
              " 'type': 'tool_call'}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculator_tool.invoke({\"expression\": \"(2+3*i)**2\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j4HPKpAVNa4S",
        "outputId": "ac134d97-0076-416c-cd1f-9d55c101bb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(-5+12j)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(llm, [calculator_tool])\n",
        "\n",
        "for event in agent.stream({\"messages\": [(\"user\", \"How much is (2+3i)^2\")]}, stream_mode=\"updates\"):\n",
        "    for _, event_values in event.items():\n",
        "      for message in event_values[\"messages\"]:\n",
        "        message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaHzFTmQNsS_",
        "outputId": "f82fa735-e367-4d90-c5c0-e9902d4c1dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  calculator (71deb34a-e1b5-4a5a-8981-dd1a350a803b)\n",
            " Call ID: 71deb34a-e1b5-4a5a-8981-dd1a350a803b\n",
            "  Args:\n",
            "    __arg1: (2+3*i)**2\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: calculator\n",
            "\n",
            "(-5+12j)\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "(2+3i)^2 is -5+12j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Calculates a single mathematical expression, incl. complex numbers.\"\"\"\n",
        "    return str(ne.evaluate(expression.strip(), local_dict={}))\n",
        "\n",
        "calculator_tool = StructuredTool.from_function(\n",
        "    func=calculator,\n",
        "    handle_tool_error=True\n",
        ")\n",
        "\n",
        "agent = create_react_agent(llm, [calculator_tool])\n",
        "\n",
        "for event in agent.stream({\"messages\": [(\"user\", \"How much is (2+3i)^2\")]}, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGC66SuhNpsL",
        "outputId": "8b75e65b-ffb1-49ee-ae76-c16a38213c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How much is (2+3i)^2\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  calculator (bfb64e58-cc77-4814-b507-363a9460cc5e)\n",
            " Call ID: bfb64e58-cc77-4814-b507-363a9460cc5e\n",
            "  Args:\n",
            "    expression: (2+3i)^2\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: calculator\n",
            "\n",
            "Error: SyntaxError('invalid decimal literal', ('<expr>', 1, 4, '(2+3i)^2', 1, 4))\n",
            " Please fix your mistakes.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I am sorry, I cannot calculate this expression because it contains a syntax error. Please provide a valid mathematical expression.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Controlled generation"
      ],
      "metadata": {
        "id": "rIcYnD7GWVHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Step(BaseModel):\n",
        "    \"\"\"A step that is a part of the plan to solve the task.\"\"\"\n",
        "    step: str = Field(description=\"Description of the step\")\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    \"\"\"A plan to solve the task.\"\"\"\n",
        "    steps: list[Step]\n",
        "\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Prepare a step-by-step plan to solve the given task.\\n\"\n",
        "    \"TASK:\\n{task}\\n\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "WxRWvU6mWV_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1 = llm.with_structured_output(Plan)"
      ],
      "metadata": {
        "id": "73ZaKWu058Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "substituted_prompt = prompt.invoke(\"How to write a bestseller on Amazon about generative AI?\")"
      ],
      "metadata": {
        "id": "_KpPpJUS6GG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1.invoke(substituted_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzPWj6jC6PAe",
        "outputId": "533c3809-7d48-44ce-802d-41366f0edf8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Plan(steps=[Step(step='Step 1: Research current bestsellers in the AI and technology categories on Amazon. Analyze their writing style, target audience, and topics covered.'), Step(step=\"Step 2: Identify a unique angle or niche within generative AI that isn't already saturated in the market. Consider focusing on a specific application, ethical implications, or future trends.\"), Step(step='Step 3: Develop a detailed outline for the book, including chapter titles, subheadings, and key concepts to be covered. Ensure a logical flow and clear structure.'), Step(step='Step 4: Write the book, focusing on clear, concise language that is accessible to a broad audience. Use real-world examples, case studies, and practical applications to illustrate key concepts.'), Step(step='Step 5: Edit and proofread the book thoroughly to ensure accuracy, clarity, and grammatical correctness. Consider hiring a professional editor.'), Step(step=\"Step 6: Design an eye-catching cover that accurately reflects the book's content and appeals to the target audience. Research successful book covers in the AI and technology genres.\"), Step(step=\"Step 7: Format the book for Kindle Direct Publishing (KDP) according to Amazon's guidelines. Optimize the book's metadata, including title, subtitle, keywords, and description, to improve search visibility.\"), Step(step='Step 8: Develop a pre-launch marketing strategy to generate buzz and build anticipation for the book. This may include creating a website or blog, engaging on social media, and reaching out to influencers.'), Step(step='Step 9: Launch the book on Amazon and monitor its performance closely. Respond to reviews, engage with readers, and adjust the marketing strategy as needed.'), Step(step='Step 10: Continuously promote the book through various channels, such as Amazon Ads, social media marketing, and email marketing. Consider running promotions and offering discounts to boost sales.')])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm.with_structured_output(Plan)\n",
        "result = chain.invoke(\"How to write a bestseller on Amazon about generative AI?\")\n",
        "assert isinstance(result, Plan)\n",
        "print(f\"Amount of steps: {len(result.steps)}\")\n",
        "for step in result.steps:\n",
        "  print(step.step)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cri0nf3CWoMZ",
        "outputId": "8bb801b0-c263-4a3e-9e6d-ae1a9626eb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of steps: 12\n",
            "Research current bestsellers in the AI and generative AI categories on Amazon to identify popular topics, writing styles, and keywords.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(Plan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhsJAMnZ5eX-",
        "outputId": "73add84a-acba-42fd-8aca-865b8f073975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pydantic._internal._model_construction.ModelMetaclass"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in result.steps:\n",
        "  print(step.step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKu6NeQG5bBs",
        "outputId": "0a76882f-8db8-4966-ca4e-1f9d1aeaf892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research current bestsellers in the AI and generative AI categories on Amazon to identify popular topics, writing styles, and keywords.\n",
            "Define the target audience and tailor the book's content and language to their level of understanding and interests.\n",
            "Develop a unique angle or perspective on generative AI that differentiates the book from existing literature.\n",
            "Create a detailed outline of the book, covering key concepts, applications, and potential future developments in generative AI.\n",
            "Write engaging and informative content, incorporating real-world examples, case studies, and practical tips.\n",
            "Optimize the book for Amazon's search algorithm by using relevant keywords in the title, subtitle, and description.\n",
            "Design an eye-catching cover that accurately reflects the book's content and appeals to the target audience.\n",
            "Format the book for Kindle and paperback versions, ensuring readability and accessibility on various devices.\n",
            "Proofread and edit the book thoroughly to eliminate errors and improve clarity.\n",
            "Launch the book on Amazon and promote it through social media, email marketing, and other channels.\n",
            "Gather reviews and feedback from readers to improve the book's content and marketing strategy.\n",
            "Continuously update the book with new information and developments in the field of generative AI to maintain its relevance and appeal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Plan.model_json_schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK3McXSmWrHA",
        "outputId": "8e3a4718-81d9-4fb9-ebda-c26117b88222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'$defs': {'Step': {'description': 'A step that is a part of the plan to solve the task.',\n",
              "   'properties': {'step': {'description': 'Description of the step',\n",
              "     'title': 'Step',\n",
              "     'type': 'string'}},\n",
              "   'required': ['step'],\n",
              "   'title': 'Step',\n",
              "   'type': 'object'}},\n",
              " 'description': 'A plan to solve the task.',\n",
              " 'properties': {'steps': {'items': {'$ref': '#/$defs/Step'},\n",
              "   'title': 'Steps',\n",
              "   'type': 'array'}},\n",
              " 'required': ['steps'],\n",
              " 'title': 'Plan',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "TndH-iMoXjs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "llm1 = ChatVertexAI(model_name=\"gemini-2.5-pro\", project=\"kuligin-sandbox1\")\n",
        "\n",
        "plan_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"OBJECT\",\n",
        "          \"properties\": {\n",
        "              \"step\": {\"type\": \"STRING\"},\n",
        "          },\n",
        "      },\n",
        "}\n",
        "\n",
        "query = \"How to write a bestseller on Amazon about generative AI?\"\n",
        "result = (prompt | llm1.with_structured_output(schema=plan_schema, method=\"json_mode\")).invoke(query)"
      ],
      "metadata": {
        "id": "4-zj59-FX_2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(isinstance(result, list))\n",
        "print(f\"Amount of steps: {len(result)}\")\n",
        "print(result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrVI4p00YLFq",
        "outputId": "6a728fc9-51f3-4046-81a9-0e26f58aa47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of steps: 8\n",
            "{'step': \"Phase 1: Research and Niche Identification. Analyze current Amazon bestsellers in the 'AI' and 'Technology' categories. Identify gaps in the market, popular sub-topics (e.g., AI for business, ethics, prompt engineering), and define a specific target audience (e.g., marketers, developers, entrepreneurs).\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "llm_json = ChatVertexAI(project=\"kuligin-sandbox1\", model_name=\"gemini-2.5-pro\",\n",
        "                        response_mime_type=\"application/json\",\n",
        "                        response_schema=plan_schema)\n",
        "result = (prompt | llm_json | JsonOutputParser()).invoke(query)\n",
        "assert(isinstance(result, list))\n",
        "print(f\"Amount of steps: {len(result)}\")\n",
        "print(result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbN3DZRjX82A",
        "outputId": "6c20918b-3d8e-4e3f-b5f7-3603790387cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of steps: 9\n",
            "{'step': 'Phase 1: Research and Niche Identification. Analyze existing generative AI books on Amazon to find a unique angle. Identify your target audience (e.g., beginners, business leaders, artists) and what specific problem your book will solve for them.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "response_schema = {\"type\": \"STRING\", \"enum\": [\"positive\", \"negative\", \"neutral\"]}\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Classify the tone of the following customer's review:\"\n",
        "    \"\\n{review}\\n\"\n",
        ")\n",
        "\n",
        "review = \"I like this movie!\"\n",
        "llm_enum = ChatVertexAI(project=\"kuligin-sandbox1\", model_name=\"gemini-1.5-pro-002\",\n",
        "                        response_mime_type=\"text/x.enum\",\n",
        "                        response_schema=response_schema)\n",
        "result = (prompt | llm_enum | StrOutputParser()).invoke(review)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "184WuJ7uXxjn",
        "outputId": "338af12d-1d18-4588-c8eb-079f876d8a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plan_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"OBJECT\",\n",
        "          \"properties\": {\n",
        "              \"step\": {\"type\": \"STRING\"},\n",
        "          },\n",
        "      },\n",
        "}\n",
        "\n",
        "query = \"How to write a bestseller on Amazon about generative AI?\"\n",
        "result = (prompt | llm.with_structured_output(schema=plan_schema, method=\"json_mode\")).invoke(query)"
      ],
      "metadata": {
        "id": "sRu-hfd-WzQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(isinstance(result, list))\n",
        "print(f\"Amount of steps: {len(result)}\")\n",
        "print(result[0])"
      ],
      "metadata": {
        "id": "6OXoubH0W1bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9944a0-8635-441c-d3f4-f95d61c59885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of steps: 1\n",
            "{'step': 'Inquisitive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "llm_json = ChatVertexAI(model_name=\"gemini-2.5-pro\", project=\"kuligin-sandbox1\", response_mime_type=\"application/json\", response_schema=plan_schema)\n",
        "result = (prompt | llm_json | JsonOutputParser()).invoke(query)\n",
        "assert(isinstance(result, list))\n",
        "print(f\"Amount of steps: {len(result)}\")\n",
        "print(result[0])"
      ],
      "metadata": {
        "id": "PUb6rsG5XY2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9114b5-195c-4b07-8abb-a772129fc0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of steps: 1\n",
            "{'step': \"The customer's tone is inquisitive and neutral, not a review of a product or service. They are asking a question seeking information or guidance.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CKcJiGdXbfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan-and-solve agent"
      ],
      "metadata": {
        "id": "JaiB_FomQ_RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    \"\"\"Plan to follow in future\"\"\"\n",
        "\n",
        "    steps: list[str] = Field(\n",
        "        description=\"different steps to follow, should be in sorted order\"\n",
        "    )\n",
        "\n",
        "system_prompt_template = (\n",
        "    \"For the given task, come up with a step by step plan.\\n\"\n",
        "    \"This plan should involve individual tasks, that if executed correctly will \"\n",
        "    \"yield the correct answer. Do not add any superfluous steps.\\n\"\n",
        "    \"The result of the final step should be the final answer. Make sure that each \"\n",
        "    \"step has all the information needed - do not skip steps.\"\n",
        ")\n",
        "planner_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt_template),\n",
        "     (\"user\", \"Prepare a plan how to solve the following task:\\n{task}\\n\")])\n",
        "\n",
        "planner = planner_prompt | ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\", temperature=1.0, google_api_key=google_api_key\n",
        ").with_structured_output(Plan)"
      ],
      "metadata": {
        "id": "JqH_u8NHRBt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"Write a strategic one-pager of building an AI startup?\"\n",
        "plan = planner.invoke(task)"
      ],
      "metadata": {
        "id": "L0Dh4s8SRNTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP0yIVK7bJs6",
        "outputId": "166eee29-e902-42cf-afd8-e9c902a9389c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Plan(steps=[\"Define the AI startup's vision and mission, clearly articulating its core purpose and long-term goal, specifically what problem it aims to solve with AI.\", 'Identify the specific, significant problem the AI startup will address, providing context on its impact and why existing solutions are inadequate.', 'Outline the AI-powered solution, describing the core AI technology or approach that will solve the identified problem, highlighting its innovative aspects and how it works at a high level.', 'Define the target market, identifying the ideal customer segment for the AI solution and estimating the market size or potential.', 'Articulate the competitive advantage, explaining what makes the AI startup unique and defensible, such as proprietary data, unique algorithms, specialized team expertise, or a novel application of AI.', 'Develop the business model, describing how the AI startup will generate revenue (e.g., SaaS, licensing, subscription, service fees).', 'Summarize the go-to-market strategy, briefly explaining how the AI product will reach its target customers (e.g., direct sales, partnerships, digital marketing).', \"Highlight key team expertise, briefly mentioning the core team's relevant experience, particularly in AI, machine learning, or the specific industry domain.\", 'Condense and refine all developed content to be concise, impactful, and fit onto a single page, ensuring a clear and logical flow for the one-pager format.', \"Review and finalize the one-pager for clarity, grammar, strategic alignment, and overall effectiveness in communicating the AI startup's vision and plan.\"])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=google_api_key)\n",
        "tools = load_tools(\n",
        "  tool_names=[\"ddg-search\", \"arxiv\", \"wikipedia\"],\n",
        "  llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "baMKWyBbRWaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.managed import IsLastStep\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class StepState(AgentState):\n",
        "  plan: str\n",
        "  step: str\n",
        "  task: str\n",
        "\n",
        "system_prompt = (\n",
        "    \"You're a smart assistant that carefully helps to solve complex tasks.\\n\"\n",
        "    \" Given a general plan to solve a task and a specific step, work on this step. \"\n",
        "    \" Don't assume anything, keep in minds things might change and always try to \"\n",
        "    \"use tools to double-check yourself.\\m\"\n",
        "    \" Use a calculator for mathematical computations, use Search to gather\"\n",
        "    \"for information about common facts, fresh events and news, use Arxiv to get \"\n",
        "    \"ideas on recent research and use Wikipedia for common knowledge.\"\n",
        ")\n",
        "\n",
        "step_template = (\n",
        "    \"Given the task and the plan, try to execute on a specific step of the plan.\\n\"\n",
        "    \"TASK:\\n{task}\\n\\nPLAN:\\n{plan}\\n\\nSTEP TO EXECUTE:\\n{step}\\n\"\n",
        ")\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", step_template),\n",
        "])\n",
        "\n",
        "execution_agent = create_react_agent(model=llm, tools=tools+[calculator_tool], state_schema=StepState, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "TA1NJIb2RR4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c12897-949c-421e-ddd5-4b51fd9ed05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:17: SyntaxWarning: invalid escape sequence '\\m'\n",
            "<>:17: SyntaxWarning: invalid escape sequence '\\m'\n",
            "/tmp/ipython-input-678506150.py:17: SyntaxWarning: invalid escape sequence '\\m'\n",
            "  \"use tools to double-check yourself.\\m\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PlanState(TypedDict):\n",
        "    task: str\n",
        "    plan: Plan\n",
        "    past_steps: Annotated[list[str], add]\n",
        "    final_response: str\n",
        "\n",
        "\n",
        "def get_current_step(state: PlanState) -> int:\n",
        "  \"\"\"Returns the number of current step to be executed.\"\"\"\n",
        "  return len(state.get(\"past_steps\", []))\n",
        "\n",
        "def get_full_plan(state: PlanState) -> str:\n",
        "  \"\"\"Returns formatted plan with step numbers and past results.\"\"\"\n",
        "  full_plan = []\n",
        "  for i, step in enumerate(state[\"plan\"].steps):\n",
        "    full_step = f\"# {i+1}. Planned step: {step}\\n\"\n",
        "    if i < get_current_step(state):\n",
        "      full_step += f\"Result: {state['past_steps'][i]}\\n\"\n",
        "    full_plan.append(full_step)\n",
        "  return \"\\n\".join(full_plan)"
      ],
      "metadata": {
        "id": "gLJE-s-FSJ32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = PromptTemplate.from_template(\n",
        "    \"You're a helpful assistant that has executed on a plan.\"\n",
        "    \"Given the results of the execution, prepare the final response.\\n\"\n",
        "    \"Don't assume anything\\nTASK:\\n{task}\\n\\nPLAN WITH RESUlTS:\\n{plan}\\n\"\n",
        "    \"FINAL RESPONSE:\\n\"\n",
        ")\n",
        "\n",
        "async def _build_initial_plan(state: PlanState) -> PlanState:\n",
        "  plan = await planner.ainvoke(state[\"task\"])\n",
        "  return {\"plan\": plan}\n",
        "\n",
        "async def _run_step(state: PlanState) -> PlanState:\n",
        "  plan = state[\"plan\"]\n",
        "  current_step = get_current_step(state)\n",
        "  step = await execution_agent.ainvoke({\"plan\": get_full_plan(state), \"step\": plan.steps[current_step], \"task\": state[\"task\"]})\n",
        "  return {\"past_steps\": [step[\"messages\"][-1].content]}\n",
        "\n",
        "async def _get_final_response(state: PlanState) -> PlanState:\n",
        "  final_response = await (final_prompt | llm).ainvoke({\"task\": state[\"task\"], \"plan\": get_full_plan(state)})\n",
        "  return {\"final_response\": final_response}\n",
        "\n",
        "\n",
        "def _should_continue(state: PlanState) -> Literal[\"run\", \"response\"]:\n",
        "  if get_current_step(state) < len(state[\"plan\"].steps):\n",
        "    return \"run\"\n",
        "  return \"response\"\n",
        "\n",
        "builder = StateGraph(PlanState)\n",
        "builder.add_node(\"initial_plan\", _build_initial_plan)\n",
        "builder.add_node(\"run\", _run_step)\n",
        "builder.add_node(\"response\", _get_final_response)\n",
        "\n",
        "builder.add_edge(START, \"initial_plan\")\n",
        "builder.add_edge(\"initial_plan\", \"run\")\n",
        "builder.add_conditional_edges(\"run\", _should_continue)\n",
        "builder.add_edge(\"response\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "AZy2UXVXSOsv",
        "outputId": "7eecbfcd-d5ed-4945-fc85-9f7a489f5e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(execution_agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "kG28IHL4D_P0",
        "outputId": "c842f46c-17e5-4189-f66f-20ecc250ea22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"Write a strategic one-pager of building an AI startup\"\n",
        "result = await graph.ainvoke({\"task\": task})"
      ],
      "metadata": {
        "id": "Z5P4NhzcSU9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359f402f-31f1-407f-a4f6-7a96c3da3f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "GraphRecursionError",
          "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3909633886.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Write a strategic one-pager of building an AI startup\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m         async for chunk in self.astream(\n\u001b[0m\u001b[1;32m   3113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3114\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mastream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m                     async for _ in runner.atick(\n\u001b[0m\u001b[1;32m   2940\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36matick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 await arun_with_retry(\n\u001b[0m\u001b[1;32m    296\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m                         \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                             input = await asyncio.create_task(\n\u001b[0m\u001b[1;32m    707\u001b[0m                                 \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0;32mawait\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-360420128.py\u001b[0m in \u001b[0;36m_run_step\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mplan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plan\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mexecution_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"plan\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_full_plan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"task\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"past_steps\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m         async for chunk in self.astream(\n\u001b[0m\u001b[1;32m   3113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3114\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mastream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2975\u001b[0m                     \u001b[0merror_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mErrorCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPH_RECURSION_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2976\u001b[0m                 )\n\u001b[0;32m-> 2977\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mGraphRecursionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2978\u001b[0m             \u001b[0;31m# set final channel values as run output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"final_response\"].content)"
      ],
      "metadata": {
        "id": "hQzhzs9jTAmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async for output in graph.astream({\"task\": task}, stream_mode=\"updates\"):\n",
        "    for key, value in output.items():\n",
        "        print(f\"Output from node '{key}':\")\n",
        "        print(\"---\")\n",
        "        print(value)\n",
        "    print(\"\\n---\\n\")"
      ],
      "metadata": {
        "id": "hquWZOUKSYL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "B32qL0-kgLvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_vertexai langsmith langchain-google-genai duckduckgo-search langchain-community langgraph arxiv wikipedia ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MeiGwF8wgNFQ",
        "outputId": "8930aa23-5b53-459b-f9cf-456a219d1c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_google_vertexai\n",
            "  Downloading langchain_google_vertexai-2.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.27)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting arxiv\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ddgs\n",
            "  Downloading ddgs-9.5.5-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting langchain-core>=0.3.76 (from langchain_google_vertexai)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform>=1.97.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_vertexai) (1.111.0)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=2.18 in /usr/local/lib/python3.12/dist-packages (from langchain_google_vertexai) (2.19.0)\n",
            "Requirement already satisfied: httpx<1,>=0.28 in /usr/local/lib/python3.12/dist-packages (from langchain_google_vertexai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<1,>=0.4 in /usr/local/lib/python3.12/dist-packages (from langchain_google_vertexai) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.9 in /usr/local/lib/python3.12/dist-packages (from langchain_google_vertexai) (2.11.7)\n",
            "Collecting validators<1,>=0.22 (from langchain_google_vertexai)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: bottleneck<2,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_google_vertexai) (1.4.2)\n",
            "Requirement already satisfied: numexpr<3,>=2.8.6 in /usr/local/lib/python3.12/dist-packages (from langchain_google_vertexai) (2.11.0)\n",
            "Collecting pyarrow<22,>=19.0.1 (from langchain_google_vertexai)\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.3)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.24.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests>=2.0.0 (from langsmith)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
            "  Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (3.37.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (1.34.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3,>=2.18->langchain_google_vertexai) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3,>=2.18->langchain_google_vertexai) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3,>=2.18->langchain_google_vertexai) (1.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.28->langchain_google_vertexai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.28->langchain_google_vertexai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.28->langchain_google_vertexai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.28->langchain_google_vertexai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.28->langchain_google_vertexai) (0.16.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.76->langchain_google_vertexai) (1.33)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.9->langchain_google_vertexai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.9->langchain_google_vertexai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.9->langchain_google_vertexai) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (0.14.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.28->langchain_google_vertexai) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.76->langchain_google_vertexai) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform>=1.97.0->langchain_google_vertexai) (1.17.0)\n",
            "Downloading langchain_google_vertexai-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.10-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading ddgs-9.5.5-py3-none-any.whl (37 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: wikipedia, sgmllib3k\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=af6ab5c8403ac6fd0cfa9fee39c1fe554aacc0c6fc8aac385268a32b879e139a\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=0af505ce960d40a4472cc6ad0efd2421dc77ceed5e569b21ed4972e56b163916\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built wikipedia sgmllib3k\n",
            "Installing collected packages: sgmllib3k, filetype, validators, requests, pyarrow, primp, ormsgpack, mypy-extensions, marshmallow, lxml, feedparser, wikipedia, typing-inspect, duckduckgo-search, ddgs, arxiv, langgraph-sdk, dataclasses-json, langchain-core, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph, langchain_google_vertexai, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 5.4.0\n",
            "    Uninstalling lxml-5.4.0:\n",
            "      Successfully uninstalled lxml-5.4.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arxiv-2.2.0 dataclasses-json-0.6.7 ddgs-9.5.5 duckduckgo-search-8.1.1 feedparser-6.0.12 filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-community-0.3.29 langchain-core-0.3.76 langchain-google-genai-2.1.10 langchain_google_vertexai-2.1.0 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 lxml-6.0.1 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 primp-0.15.0 pyarrow-21.0.0 requests-2.32.5 sgmllib3k-1.0.0 typing-inspect-0.9.0 validators-0.35.0 wikipedia-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "6d267bea9a3840d99c9a118be631cce3"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}